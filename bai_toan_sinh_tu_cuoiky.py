# -*- coding: utf-8 -*-
"""BAI_TOAN_SINH_TU_CUOIKY.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1c2lkJrXvfAgP2PXNxUTNrPxMSFjhiA-Q
"""

!wget --no-check-certificate \
    https://storage.googleapis.com/protonx-cloud-storage/data.txt
data = open('data.txt').read()

from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.models import Sequential
from tensorflow.keras.optimizers import Adam
from tensorflow.keras import regularizers
import tensorflow.keras.utils as ku 
import numpy as np

corpus = data.lower().split("\n")

corpus

"""Yêu cầu: Sinh từ tiếp khi gõ bất cứ một câu nào có chiều dài bất kỳ."""

# Dự đoán 10 từ tiếp theo
# despite of wrinkles -> this thy golden time to heart's sight ' must '
tokenizer = Tokenizer()
tokenizer.fit_on_texts(corpus)
total_words = len(tokenizer.word_index) + 1

# create input sequences using list of tokens, Tạo chuỗi đầu vào bằng cách sử dụng danh sách mã thông báo:
input_sequences = []
for line in corpus:
  token_list = tokenizer.texts_to_sequences([line])[0]
  for i in range(1, len(token_list)):
    n_gram_sequence = token_list[:i+1]
    print(n_gram_sequence)
    input_sequences.append(n_gram_sequence)

tokenizer.word_index

"""1. Xử lý dữ liệu. Chia features, label"""

# pad sequences 
max_sequence_len = max([len(x) for x in input_sequences])
input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))

# create predictors and label
predictors, label = input_sequences[:,:-1],input_sequences[:,-1]
print(label)
label = ku.to_categorical(label, num_classes=total_words)
#Int32 -- (-2,147,483,648 to +2,147,483,647)

predictors

"""2. Xây dựng model
Yêu cầu độ chính xác: 80%
"""

model = Sequential()
model.add(Embedding(total_words, 100, input_length=max_sequence_len-1))
model.add(Bidirectional(LSTM(150, return_sequences = True)))
model.add(Dropout(0.2))
model.add(LSTM(100))
model.add(Dense(total_words/2, activation='relu', kernel_regularizer=regularizers.l2(0.01)))
model.add(Dense(total_words, activation='softmax'))
model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
print(model.summary())
# 100 là chiều mà chúng ta muốn mô tả cái từ
# x=100

history = model.fit(predictors, label, epochs=100, verbose=1)

"""3. Dự đoán 10 từ tiếp theo"""

test_seq = 'despite of wrinkles'
# 'despite of wrinkles this thy' -> 'golden'
# sinh ra 10 từ tiếp theo sau test_seq
# despite of wrinkles this thy golden time to heart's sight ' must '
next_words = 10

for _ in range(next_words):
  token_list = tokenizer.texts_to_sequences([test_seq])[0]
  token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')
  predicted = model.predict_classes(token_list, verbose=0)
  output_word = ""
  for word, index in tokenizer.word_index.items():
    if index == predicted:
      output_word = word
      break
  test_seq += " " + output_word
print(test_seq)